{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Clustering with Scikit-Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outline\n",
    "\n",
    "- [1. Load Dataset](#1)\n",
    "- [2. Hierarchical Clustering](#3)\n",
    "- [3. DBScan](#4)\n",
    "- [4. Chameleon clusters data](#5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, run the following cell to import some useful libraries to complete this Lab. If not already done, you must install them in your virtual environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import DBSCAN, AgglomerativeClustering\n",
    "from sklearn.metrics import silhouette_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the previous cell outputs one the following error: `ModuleNotFoundError: No module named 'sklearn'`, then, you have to install the Scikit-Learn package. If you don't remember how to install a Python package, please retrieve the guide on Anaconda-Navigator.\n",
    "\n",
    "To install **sklearn** you can use one of the following commands from the terminal of your virtual environment: <br>\n",
    "`pip install -U scikit-learn` <br>\n",
    "`conda install -c intel scikit-learn`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1'></a>\n",
    "## 1. Load dataset\n",
    "\n",
    "### Exercise 1\n",
    "Firstly, you will load the first dataset for this lab. Read the csv file from the following path `\"data_lab5/lab5_data.csv\"` into a DataFrame `df`. The separator of the csv file is the comma `,`. You should skip the header of the first row (i.e., skip the first row) and set the column names to the list stored in the variable `columns`.\n",
    "\n",
    "<details>    \n",
    "<summary>\n",
    "    <font size=\"3\" color=\"darkgreen\"><b>Hints</b></font>\n",
    "</summary>\n",
    "<p>\n",
    "<ul>\n",
    "    <li>To read a csv file into a DataFrame, you can use pd.read_csv().</li>\n",
    "    <li>To specify the <strong>separator</strong>, you can set the 'set' parameter.</li>\n",
    "    <li>To specify the <strong>column names</strong>, you can set the 'names' parameter.</li>\n",
    "    <li>To specify the <strong>number of rows to skip</strong>, you can set the 'skiprows' parameter.</li>\n",
    "</ul>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['x', 'y', 'gt']\n",
    "\n",
    "#### START CODE HERE ####\n",
    "#### Approximately 1 line ####\n",
    "\n",
    "#### END CODE HERE ####\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Expected output\n",
    "```                x\t         y     gt```<br>\n",
    "```0\t516.012706\t393.014514\t0```<br>\n",
    "```1\t436.211762\t408.656585\t0```<br>\n",
    "```2\t512.052601\t372.022014\t0```<br>\n",
    "```3\t489.140464\t401.807159\t0```<br>\n",
    "```4\t446.207986\t338.516682\t0```<br>\n",
    "```...\t       ...\t       ...    ...```<br>\n",
    "```331\t638.916471\t323.569096\t1```<br>\n",
    "```332\t542.005901\t347.527070\t0```<br>\n",
    "```333\t611.964612\t377.254978\t0```<br>\n",
    "```334\t520.654168\t455.996453\t0```<br>\n",
    "```335\t594.479314\t392.901455\t0```<br>\n",
    "```336 rows × 3 columns```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is composed of the `x` and `y` coordinates for 336 points, and the True label in the column `gt`.\n",
    "The next cell will create a DataFrame with the **input features** (i.e., all the `x` and `y` coordinates of the points) into a new DataFrame `df_X`, and a Series containing the **ground-truth labels** `gt_series`. Run the next cell to create the DataFrame and the Series. Notice that, in this case, we also have the **true labels**. Normally, when using clustering, the true labels are **not** available. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X = df[[\"x\",\"y\"]].copy()\n",
    "gt_series = df[\"gt\"].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell defines a function that takes a DataFrames in input, and plots the scatter plot (i.e., the points) contained in the `x` and `y` columns. Run the next cell to define the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_2d_scatter(df, title=\"\"): \n",
    "    \"\"\"Display a 2D scatter plot\n",
    "    :param df: input data points, DataFrame ('x' and 'y' coordinates in the first and second column, respectively)\n",
    "    :return: fig, ax, objects\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(6, 5), dpi=90) \n",
    "    ax.scatter(df.iloc[:,0], df.iloc[:,1])\n",
    "    ax.set_xlabel(\"x\", fontsize=14)\n",
    "    ax.set_ylabel(\"y\", fontsize=14)\n",
    "    ax.set_title(title)\n",
    "    ax.grid(True)\n",
    "    return fig, ax # use them for further modifications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell calls the previously defined function and **plots all the points in the input dataset in the plane**. All points are plotted with the same color because you still have not applied clustering. Run the next cell to plot all the points in the plane."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _ = plot_2d_scatter(df_X, \"Points in the plane\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that, with 2-dimensional data (like in this case), you can easily visualize the number of clusters because you can plot the points in a plane. In this case, it is reasonable to think that there are 3 distinct clusters. However, the procedure that we will apply in this notebook can also be applied with **higher dimensional data**, which is not visualizable in a plane. Therefore, for high dimensional data, it is challenging to visualize the correct number of clusters. You have to select the best number of clusters based on the analysis of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell defines a function that visualizes each cluster in a plane with a different color. It takes as parameters the points stored in a DataFrame `df` with the $x$ and $y$ coordinates of points stored in the `x` and `y` columns, respectively, the list with the predicted cluster id for each point `y_pred`, and an optional plot title `title`. Run the next cell to define the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_2d_scatter_with_clusters(df, y_pred, title=\"\"): \n",
    "    \"\"\"Display a 2D scatter plot with each cluster with a different color\n",
    "    :param df: input data points, DataFrame ('x' and 'y' coordinates in the 'x' and 'y' columns, respectively)\n",
    "    :param y_pred: numpy array with the predicted label for each pointù\n",
    "    :param title: string containing the title of the chart\n",
    "    :return: fig, ax, objects\n",
    "    \"\"\"    \n",
    "    fig, ax = plt.subplots(figsize=(6, 5), dpi=90) \n",
    "    ax.set_xlabel(\"x\", fontsize=14)\n",
    "    ax.set_ylabel(\"y\", fontsize=14)\n",
    "    \n",
    "    n_clusters = list(set(y_pred)) \n",
    "    labels = [f\"Cluster {c}\" for c in n_clusters]\n",
    "    \n",
    "    for i, label in enumerate(n_clusters):\n",
    "        \n",
    "        if label == -1:\n",
    "            label_name = \"Outliers\"\n",
    "        else:\n",
    "            label_name = labels[i]\n",
    "\n",
    "        #add data points \n",
    "        ax.scatter(x=df.loc[y_pred==label, 'x'], \n",
    "                    y=df.loc[y_pred==label,'y'], \n",
    "                    alpha=0.7, label=label_name)\n",
    "        \n",
    "    ax.legend(loc=(1.1, 0.5))\n",
    "    ax.set_title(title)\n",
    "    ax.grid(True)\n",
    "    \n",
    "    return fig, ax # use them for further modifications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, we will plot the points with a different color based on the **ground-truth labels** present in the dataset. As discussed before, this dataset contains the true labels. However, the true labels are usually **not** available when performing clustering. We can see that there are **3 well-separated different clusters**. However, some **noise** is present in the clusters (i.e., some green points are closer to the blue cluster than to the green one, etc.). \n",
    "\n",
    "Run the next cell to plot the points based on the ground-truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _ = plot_2d_scatter_with_clusters(df_X, gt_series, \"Ground-Truth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3'></a>\n",
    "## 2. Hierarchical Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, is already provided to you the code to run the **Hierarchical clustering**. Run the next cells to perform the hierarchical clustering. The dendrogram of the hierarchical clustering is automatically cut to match the `n_clusters` specified. You can read the documentation of the agglomerative clustering <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.cluster.AgglomerativeClustering.html\" >here</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = 3\n",
    "hc = AgglomerativeClustering(#FIXME#)\n",
    "y_pred_hc = hc.fit_predict(#FIXME#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _ = plot_2d_scatter_with_clusters(df_X, y_pred_hc, f\"Hierarchical Clustering with {n_clusters} clusters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "silh_avg_hc = silhouette_score(#FIXME#, y_pred_hc)\n",
    "print(silh_avg_hc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that the result is practically the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='4'></a>\n",
    "## 3. DBScan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, is already provided to you the code to run the **Density-based clustering (dbscan)**. Run the next cells to perform the dbscan clustering. The dbscan does not require the specification of the number of clusters. Moreover, it also identifies the outliers. However, it require the specification of two parameters: epsilon and the minimum number of points that are often difficult to set. You can read the documentation of the dbscan clustering <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.cluster.DBSCAN.html\" >here</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbscan = DBSCAN(eps=20, min_samples=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_dbscan= dbscan.#FIXME#(df_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _ = plot_2d_scatter_with_clusters(df_X, #FIXME#, \"DBScan Clustering\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The red points are the outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='5'></a>\n",
    "## 4. Chameleon clusters data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you will move to another dataset, the `chameleon_clusters` data. This time the true labels are not available.\n",
    "The next cell loads the data into a DataFrame `df_X_cc`. Please run the next cell to load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X_cc = pd.read_csv(\"data_lab5/chameleon_clusters.csv\", sep=\",\")\n",
    "df_X_cc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the next cell to plot the points in the plane."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _ = plot_2d_scatter(df_X_cc, \"Points in the plane\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that this time the points are distributed in a more complicated manner. It is also more difficult to identify the best number of clusters. In addition, there are many points that are outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "\n",
    "For this type of data with different densities, **dbscan** may be a better choice. Perform the clustering with the **dbscan** algorithm for the data stored in `df_X_cc`. Store the predicted labels in a variable `y_pred_dbscan`. Set the parameters of the DBSCAN object as follows: `eps`=10 and `min_samples`=20. Go ahead and try changing the values to see how the results change. You can read the documentation of the dbscan clustering <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.cluster.DBSCAN.html\" >here</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### START CODE HERE ####\n",
    "#### Approximately 2 line ####\n",
    "\n",
    "\n",
    "#### END CODE HERE ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, run the next cell to plot the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _ = plot_2d_scatter_with_clusters(df_X_cc, y_pred_dbscan, \"DBScan Clustering\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graphically, you can see that the DBScan seems to perform much better in this case. It can identify clusters of points and also outliers."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
